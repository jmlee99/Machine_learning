{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98f5a9e2",
   "metadata": {},
   "source": [
    "## ensemble\n",
    "\n",
    "1. 만드는 이유 : 단일 머신러닝보다 좋은 성능 ( 정확도, 속도 )\n",
    "2. 다수의 ***약한*** 머신러닝 모델을 종합하여 최종 모델로 사용\n",
    "3. 다수의 모델구축 -> 학습데이터 분할 / 재사용 필요\n",
    "4. 단일 모델들의 취합 방법, 연결 방법에 따라 종류 구분\n",
    "\n",
    ">    - ***Bagging : with replacement, independent***\n",
    ">\n",
    ">데이터를 분할에 집중 -> 확률로 따지면 반복가능 (a꺼내고 a를 다시 넣고, a를 다시 꺼낼 수 있다.)\n",
    ">\n",
    ">    - ***Boosting : without replacement, sequential***\n",
    ">\n",
    ">데이터를 썰어놓고 -> 있는 데이터를 가지고 모델1, 모델2, 모델3 ...을 만들고 각각의 모델을 직렬로 연결하는 것이다.\n",
    ">\n",
    "> 각각의 모델에 가중치를 주고 다음 모델을 만들 때 가중치다시 준다. ( 처음에 logistic이 젤 높았다면 다음에 또 유리하게 준다. )\n",
    ">\n",
    ">    - ***K-Fold Cross Validation***\n",
    ">>학습데이터를 k개로 분할\n",
    ">>\n",
    ">>검증용 분할 데이터로 순환식 사용\n",
    ">>\n",
    ">>다수의 머신러닝 결과를 (통상) 평균하여 결과 도출\n",
    ">\n",
    ">    ***- Bootstrapping ( Bagging에서의 데이터 분할 방법 )***\n",
    ">>학습데이터로 부터 n개의 학습 데이터 세트 구성\n",
    ">>\n",
    ">>랜덤 샘플링, with replacement\n",
    ">>>동일 데이터, 동일 데이터 세트에 중복 포함 가능\n",
    ">\n",
    "> **B**ootrap **Agg**regation == (Bagging)\n",
    ">\n",
    "> Boostrap 적용하여 구성한 모델의 취합\n",
    ">\n",
    "> Overfit 회피 : 과적합 회피\n",
    ">\n",
    "> Weak(약한, 정확도 낮은) 모델 여러개 개발, 취합\n",
    ">\n",
    "> Out Of Bag(OOB) : 트레이닝 데이터에는 있지만, 트레이닝 세트에 포함되어 있지 않은 데이터들 \n",
    ">\n",
    ">    ***- Boosting***\n",
    ">>다수의 학습데이터 세트 구성, without replacment ( 똑같은 학습데이터 반복 X )\n",
    ">>\n",
    ">> - 순차적 적용\n",
    ">>\n",
    ">>모델 1 개발, 개발 결과를 모델 2 개발 입력값 활용\n",
    ">>> 정확도 낮은 feature에 대해 가중치 증가\n",
    ">>>\n",
    ">>> 증가된 가중치 -> 적극적인 학습유도 (AdaBoost, Adaptive Boosting{ == 적응형})\n",
    "> - ***Gradient Tree Boosting***\n",
    ">>순차적 모델 개발 과정에서의 가중치 조절에 Gradient Decent 사용\n",
    "> - ***Histogram-Based Gradieny Boositng***\n",
    ">>분포도 사용, 예측값 구간화 -> **속도향상**\n",
    ">\n",
    "> ***- Voting***\n",
    ">\n",
    "> 다수의 개발 모델의 취합방법\n",
    ">> 1. 개별 모델의 예측값을 기초로 **투표** 실시.\n",
    ">>\n",
    ">최종 예측값 결정\n",
    ">>\n",
    ">> 2. 개별 모델/ 예측값 별 다른 가중치\n",
    ">\n",
    ">\n",
    "> ***- Stacked***\n",
    ">>다수의 개발 모델의 취합방법\n",
    ">>>개별 모델의 예측값 축적\n",
    ">>>최종적용 모델의 입력값으로 사용\n",
    ">>\n",
    ">> 다양한 종류의 개별 모델 stacking 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7547ec33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import RocCurveDisplay, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e31dab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data', header=None)\n",
    "data.head()\n",
    "\n",
    "X = data.iloc[:, 1:8]\n",
    "y = data.iloc[:, 0].astype('category').cat.codes\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify = y, random_state = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5584696",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score :  0.558109833971903\n",
      "Test score :  0.5473684210526316\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestClassifier(n_estimators = 150, max_depth = 3)\n",
    "m.fit(X_train, y_train)\n",
    "print('Train score : ', m.score(X_train, y_train))\n",
    "print('Test score : ', m.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2e5beb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier()\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "print(m.estimator_)\n",
    "print(len(m.estimators_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f9c396e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('logistic_reg', LogisticRegression(solver='liblinear')), ('NaiveBayes', GaussianNB()), ('DecisionTree', DecisionTreeClassifier(max_depth=7))]\n",
      "Train score :  0.5743933588761175\n",
      "Test score :  0.5320574162679426\n"
     ]
    }
   ],
   "source": [
    "classifiers = [LogisticRegression(solver = 'liblinear'), GaussianNB(), DecisionTreeClassifier(max_depth = 7)]\n",
    "classifier_names = ['logistic_reg', 'NaiveBayes', 'DecisionTree']\n",
    "est = []\n",
    "\n",
    "for n, c in zip(classifier_names, classifiers):\n",
    "    est.append((n, c))\n",
    "print(est)\n",
    "    \n",
    "m = VotingClassifier(est)\n",
    "m.fit(X_train, y_train)\n",
    "\n",
    "print('Train score : ', m.score(X_train, y_train))\n",
    "print('Test score : ', m.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
